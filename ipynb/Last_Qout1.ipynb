{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-11T16:06:11.338136Z",
     "start_time": "2024-06-11T16:06:11.114473Z"
    }
   },
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from pandas import DataFrame\n",
    "from PIL import Image\n",
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "# qdrant_client = QdrantClient(\n",
    "#     url=\"https://02cfa3da-e5fd-484e-ad1f-b17530cf0530.us-east4-0.gcp.cloud.qdrant.io:6333/\", \n",
    "#     api_key=\"ms5CTCc7UA4OnkxqZBp9KAwM2d3h-N6Cex_QVm2Icmvn1enD5IpWAQ\",\n",
    "# )\n",
    "\n",
    "qdrant_client = QdrantClient(\n",
    "    url=\"https://a7d15b9f-649d-4c0f-9433-2a6c06cc66cc.europe-west3-0.gcp.cloud.qdrant.io:6333\",\n",
    "    api_key=\"mQ3vUPBNtp0mRY6h0gTFMRncal8o1o_trEhck6tYv327wNB7c8WLHw\",\n",
    ")"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T16:06:11.345674Z",
     "start_time": "2024-06-11T16:06:11.340647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# from PIL import Image\n",
    "# from io import BytesIO\n",
    "# import math\n",
    "# import base64\n",
    "# \n",
    "# class ImageDataset:\n",
    "#     def __init__(self, base_path, num_samples_per_class=50):\n",
    "#         self.base_path = base_path\n",
    "#         self.num_samples_per_class = num_samples_per_class\n",
    "#         self.df = pd.DataFrame()\n",
    "#         self._load_data()\n",
    "# \n",
    "#     def _load_data(self):\n",
    "#         for class_id, class_path in enumerate(os.listdir(self.base_path)):\n",
    "#             class_file = os.listdir(f'{self.base_path}/{class_path}')\n",
    "#             samples_in_class = len(class_file)\n",
    "#             samples_in_class = min(samples_in_class, self.num_samples_per_class)\n",
    "#             \n",
    "#             train_samples_files = class_file[:samples_in_class]\n",
    "#             train_samples_files = list(map(lambda x: f'{self.base_path}/{class_path}/{x}', train_samples_files))\n",
    "#             \n",
    "#             payload = pd.DataFrame({\n",
    "#                 'image_path': train_samples_files,\n",
    "#                 'type': class_path\n",
    "#             })\n",
    "#             self.df = pd.concat([self.df, payload])\n",
    "# \n",
    "#     def resize_image(self, image, target_width=256):\n",
    "#         image_aspect_ratio = image.size[0] / image.size[1]\n",
    "#         resized_img = image.resize(\n",
    "#             [target_width, math.floor(target_width * image_aspect_ratio)]\n",
    "#         )\n",
    "#         return resized_img\n",
    "#     \n",
    "#     def convert_image_to_base64(self, image):\n",
    "#         buffered = BytesIO()\n",
    "#         image.save(buffered, format=\"JPEG\")\n",
    "#         return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "# \n",
    "#     def __getitem__(self, idx):\n",
    "#         if idx >= len(self.df):\n",
    "#             raise IndexError(\"Index out of range\")\n",
    "#         \n",
    "#         row = self.df.iloc[idx]\n",
    "#         image = Image.open(row['image_path'])\n",
    "#         image = self.resize_image(image)\n",
    "#         encoded_image = self.convert_image_to_base64(image)\n",
    "#         \n",
    "#         return image, row['type'], encoded_image\n",
    "# \n",
    "#     def __len__(self):\n",
    "#         return len(self.df)\n",
    "# \n",
    "# # Example usage:\n",
    "# TRAIN_BASE_PATH = '../afhq/train'\n",
    "# NUM_SAMPLE_FOR_CLASS = 50\n",
    "# \n",
    "# data = ImageDataset(TRAIN_BASE_PATH, NUM_SAMPLE_FOR_CLASS)"
   ],
   "id": "f11ab0a71bc43c1c",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T16:06:11.966015Z",
     "start_time": "2024-06-11T16:06:11.527709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# df_origin = pd.read_excel('../Data/instagram_posts.xlsx')\n",
    "# df_origin['post_date'] = df_origin['post_date'].dt.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "# df_origin['post_date']"
   ],
   "id": "7445f45e84588712",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T16:06:12.183696Z",
     "start_time": "2024-06-11T16:06:12.179660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train_files = os.listdir('../Data/instagram_photo')\n",
    "# df_matching = DataFrame({\n",
    "#     'instagram_user': [],\n",
    "#     'image_path': [],\n",
    "#     'link': [],\n",
    "# })\n",
    "# matching = []\n",
    "# for i in range(len(df_origin)):\n",
    "#     post_date = df_origin['post_date'][i]\n",
    "#     for file in train_files:\n",
    "#         if file.endswith('.jpg'):\n",
    "#             if post_date == file[:19]:\n",
    "#                 image_path = f'../Data/instagram_photo/{file}'\n",
    "#                 post_date = df_origin['post_date'][i]\n",
    "#                 instagram_user = df_origin['username'][i]\n",
    "#                 link = df_origin['post_url'][i]\n",
    "#     \n",
    "#                 matching.append({\n",
    "#                     'instagram_user': instagram_user,\n",
    "#                     'image_path': image_path,\n",
    "#                     'link': link,\n",
    "#                 })\n",
    "# \n",
    "# df_matching = pd.DataFrame(matching)\n",
    "# df_matching"
   ],
   "id": "bc1b334a6e4a1cca",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T16:37:35.921883Z",
     "start_time": "2024-06-11T16:37:33.597899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import math\n",
    "import base64\n",
    "from transformers import AutoImageProcessor, ResNetForImageClassification\n",
    "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
    "\n",
    "class InstagramPhotoMatcher:\n",
    "    def __init__(self, data_path, origin_df):\n",
    "        self.data_path = data_path\n",
    "        self.origin_df = origin_df\n",
    "        self.train_files = os.listdir(data_path)\n",
    "        self.df_matching = self.create_matching_dataframe()\n",
    "        \n",
    "        self.processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "        self.model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
    "        \n",
    "        self.collection_name = 'instagram_data'\n",
    "        # self.collection = qdrant_client.create_collection(\n",
    "        #     collection_name=self.collection_name,\n",
    "        #     vectors_config=VectorParams(\n",
    "        #         size=1000,\n",
    "        #         distance=Distance.COSINE\n",
    "        #     ),\n",
    "        # )\n",
    "\n",
    "    def create_matching_dataframe(self):\n",
    "        matching = []\n",
    "        for i in range(len(self.origin_df)):\n",
    "            post_date = self.origin_df['post_date'][i]\n",
    "            for file in self.train_files:\n",
    "                if file.endswith('.jpg') and post_date == file[:19]:\n",
    "                    image_path = os.path.join(self.data_path, file)\n",
    "                    instagram_user = self.origin_df['username'][i]\n",
    "                    full_name = self.origin_df['full_name'][i]\n",
    "                    bio = self.origin_df['biography'][i]\n",
    "                    caption = self.origin_df['post_caption'][i]\n",
    "                    link = self.origin_df['post_url'][i]\n",
    "                    matching.append({\n",
    "                        'instagram_user': instagram_user,\n",
    "                        'image_path': image_path.replace(\"\\\\\", '/'),\n",
    "                        'link': link,\n",
    "                        'full_name': full_name,\n",
    "                        'bio': bio,\n",
    "                        'caption': caption,\n",
    "                    })\n",
    "        return pd.DataFrame(matching)\n",
    "    \n",
    "    def resize_image(self, image, target_width=256):\n",
    "        image_aspect_ratio = image.size[0] / image.size[1]\n",
    "        resized_img = image.resize(\n",
    "            [target_width, math.floor(target_width * image_aspect_ratio)]\n",
    "        )\n",
    "        return resized_img\n",
    "\n",
    "    def convert_image_to_base64(self, image):\n",
    "        buffered = BytesIO()\n",
    "        image.save(buffered, format=\"JPEG\")\n",
    "        return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "    def upload_item(self, idx):\n",
    "        if idx >= len(self.df_matching):\n",
    "            raise IndexError(\"Index out of range\")\n",
    "        \n",
    "        item_data = self.__getitem__(idx)\n",
    "        row = item_data['row']\n",
    "        encoded_image = item_data['encoded_image']\n",
    "        logits = item_data['logits']\n",
    "    \n",
    "        bio = row['bio'][:512] if isinstance(row['bio'], str) else ''\n",
    "        \n",
    "        points = [\n",
    "            PointStruct(\n",
    "                id=idx,\n",
    "                payload={\n",
    "                    'instagram_user': row['instagram_user'],\n",
    "                    'image_path': row['image_path'],\n",
    "                    'link': row['link'],\n",
    "                    'full_name': row['full_name'],\n",
    "                    'bio': bio,\n",
    "                    'encoded_image': encoded_image,\n",
    "                },\n",
    "                vector=logits.flatten().tolist()\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        print(qdrant_client.upsert(\n",
    "            collection_name=self.collection_name,\n",
    "            points=points\n",
    "        ))\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.df_matching):\n",
    "            raise IndexError(\"Index out of range\")\n",
    "        \n",
    "        row = self.df_matching.iloc[idx]\n",
    "        image = Image.open(row['image_path'])\n",
    "        image = image.convert('RGB')\n",
    "        image = self.resize_image(image)\n",
    "        encoded_image = self.convert_image_to_base64(image)\n",
    "        \n",
    "        inputs = self.processor(images=image, return_tensors=\"pt\")\n",
    "        outputs = self.model(**inputs)\n",
    "        \n",
    "        return {\n",
    "            'row': row.to_dict(),\n",
    "            'image': image,\n",
    "            'encoded_image': encoded_image,\n",
    "            'logits': outputs.logits\n",
    "        }\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df_matching)\n",
    "        \n",
    "data_path = '../Data/instagram_photo'\n",
    "df_origin = pd.read_excel('../Data/instagram_posts.xlsx')\n",
    "df_origin['post_date'] = df_origin['post_date'].dt.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "matcher = InstagramPhotoMatcher(data_path, df_origin)"
   ],
   "id": "ef61d7ececa1a282",
   "execution_count": 41,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T16:22:57.805605Z",
     "start_time": "2024-06-11T16:22:55.746266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# from io import BytesIO\n",
    "# import math\n",
    "# import base64\n",
    "# from transformers import AutoImageProcessor, ResNetForImageClassification\n",
    "# from qdrant_client.models import VectorParams, Distance, PointStruct\n",
    "# \n",
    "# class InstagramPhotoMatcher:\n",
    "#     def __init__(self, data_path, origin_df):\n",
    "#         self.data_path = data_path\n",
    "#         self.origin_df = origin_df\n",
    "#         self.train_files = os.listdir(data_path)\n",
    "#         self.df_matching = self.create_matching_dataframe()\n",
    "#         \n",
    "#         self.processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "#         self.model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
    "#         \n",
    "#         self.collection_name = 'instagram_data'\n",
    "#         # self.collection = qdrant_client.create_collection(\n",
    "#         #     collection_name=self.collection_name,\n",
    "#         #     vectors_config=VectorParams(\n",
    "#         #         size=1000,\n",
    "#         #         distance=Distance.COSINE\n",
    "#         #     ),\n",
    "#         # )\n",
    "# \n",
    "#     def create_matching_dataframe(self):\n",
    "#         matching = []\n",
    "#         for i in range(len(self.origin_df)):\n",
    "#             post_date = self.origin_df['post_date'][i]\n",
    "#             for file in self.train_files:\n",
    "#                 if file.endswith('.jpg') and post_date == file[:19]:\n",
    "#                     image_path = os.path.join(self.data_path, file)\n",
    "#                     instagram_user = self.origin_df['username'][i]\n",
    "#                     full_name = self.origin_df['full_name'][i]\n",
    "#                     bio = self.origin_df['biography'][i]\n",
    "#                     caption = self.origin_df['post_caption'][i]\n",
    "#                     link = self.origin_df['post_url'][i]\n",
    "#                     matching.append({\n",
    "#                         'instagram_user': instagram_user,\n",
    "#                         'image_path': image_path.replace(\"\\\\\", '/'),\n",
    "#                         'link': link,\n",
    "#                         'full_name': full_name,\n",
    "#                         'bio': bio,\n",
    "#                         'caption': caption,\n",
    "#                     })\n",
    "#         return pd.DataFrame(matching)\n",
    "#     \n",
    "#     def resize_image(self, image, target_width=256):\n",
    "#         image_aspect_ratio = image.size[0] / image.size[1]\n",
    "#         resized_img = image.resize(\n",
    "#             [target_width, math.floor(target_width * image_aspect_ratio)]\n",
    "#         )\n",
    "#         return resized_img\n",
    "# \n",
    "#     def convert_image_to_base64(self, image):\n",
    "#         buffered = BytesIO()\n",
    "#         image.save(buffered, format=\"JPEG\")\n",
    "#         return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "# \n",
    "#     def __getitem__(self, idx):\n",
    "#         if idx >= len(self.df_matching):\n",
    "#             raise IndexError(\"Index out of range\")\n",
    "#         \n",
    "#         row = self.df_matching.iloc[idx]\n",
    "#         image = Image.open(row['image_path'])\n",
    "#         image = image.convert('RGB')\n",
    "#         image = self.resize_image(image)\n",
    "#         encoded_image = self.convert_image_to_base64(image)\n",
    "#         \n",
    "#         inputs = self.processor(images=image, return_tensors=\"pt\")\n",
    "#         outputs = self.model(**inputs)\n",
    "#         \n",
    "#         # points = [\n",
    "#         #     models.PointStruct(\n",
    "#         #         id=idx,\n",
    "#         #         payload=data_dict[idx],\n",
    "#         #         vector=embeddings[idx].flatten().tolist()\n",
    "#         #     )\n",
    "#         #     for idx, _ in enumerate(data_dict)\n",
    "#         # ]\n",
    "#         \n",
    "#         # convert bio to string and only take the first 512 characters\n",
    "#         if isinstance(row['bio'], str):\n",
    "#             bio = row['bio'][:512]\n",
    "#         else:\n",
    "#             bio = ''\n",
    "#         \n",
    "#         \n",
    "#         points = [\n",
    "#             PointStruct(\n",
    "#                 id=idx,\n",
    "#                 payload={\n",
    "#                     'instagram_user': row['instagram_user'],\n",
    "#                     'image_path': row['image_path'],\n",
    "#                     'link': row['link'],\n",
    "#                     'full_name': row['full_name'],\n",
    "#                     'bio': bio,\n",
    "#                     'encoded_image': encoded_image,\n",
    "#                 },\n",
    "#                 vector=outputs.logits.flatten().tolist()\n",
    "#             )\n",
    "#         ]\n",
    "#         \n",
    "#         qdrant_client.upsert(\n",
    "#             collection_name=self.collection_name,\n",
    "#             points=points\n",
    "#         )\n",
    "#         # data_dict[i] = {\n",
    "#         #     'instagram_user': matcher[i][0]['instagram_user'],\n",
    "#         #     'image_path': matcher[i][0]['image_path'],\n",
    "#         #     'link': matcher[i][0]['link'],\n",
    "#         #     'full_name': matcher[i][0]['full_name'],\n",
    "#         #     'bio': matcher[i][0]['bio'],\n",
    "#         #     'encoded_image': matcher[i][2],\n",
    "#         # }\n",
    "#         \n",
    "#         return self.df_matching.iloc[idx].to_dict(), image, encoded_image, outputs.logits\n",
    "#     \n",
    "#     def __len__(self):\n",
    "#         return len(self.df_matching)\n",
    "#         \n",
    "# # Usage\n",
    "# # df_origin = pd.DataFrame({...})  # Assuming df_origin is already defined\n",
    "# data_path = '../Data/instagram_photo'\n",
    "# df_origin = pd.read_excel('../Data/instagram_posts.xlsx')\n",
    "# df_origin['post_date'] = df_origin['post_date'].dt.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "# matcher = InstagramPhotoMatcher(data_path, df_origin)"
   ],
   "id": "b5a30e393f9817b0",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T16:26:27.062508Z",
     "start_time": "2024-06-11T16:22:58.177938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for i in range(1852, len(matcher)):\n",
    "#     matcher[i]"
   ],
   "id": "37a94f01ba10018b",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:43:51.651320Z",
     "start_time": "2024-06-11T15:43:51.647216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from io import BytesIO\n",
    "# import math\n",
    "# import base64\n",
    "# \n",
    "# target_width = 128\n",
    "# def resize_image(image_path):\n",
    "#     pil_img = Image.open(image_path)\n",
    "#     image_aspect_ratio = pil_img.size[0] / pil_img.size[1]\n",
    "#     resized_img = pil_img.resize(\n",
    "#         [target_width, math.floor(target_width * image_aspect_ratio)]\n",
    "#     )\n",
    "#     return resized_img\n",
    "# \n",
    "# def convert_image_to_base64(image):\n",
    "#     buffered = BytesIO()\n",
    "#     image.save(buffered, format=\"JPEG\")\n",
    "#     return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "# \n",
    "# resize_images = list(map( lambda x: resize_image(x), df_matching['image_path']))\n",
    "# base64_str = list(map( lambda x: convert_image_to_base64(x), resize_images))\n",
    "# \n",
    "# # resized_images = list(map( lambda x: resize_image(x), train_samples_files))\n",
    "# # base64_str = list(map( lambda x: convert_image_to_base64(x), resized_images))\n",
    "# # payload['image'] = base64_str"
   ],
   "id": "28d9ff9fa5d34a0c",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:43:51.658140Z",
     "start_time": "2024-06-11T15:43:51.652326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TRAIN_BASE_PATH = '../afhq/train'\n",
    "# NUM_SAMPLE_FOR_CLASS = 50\n",
    "# \n",
    "# df = pd.DataFrame()\n",
    "# for class_id, class_path in enumerate(os.listdir(TRAIN_BASE_PATH)):\n",
    "#     class_file = os.listdir(f'{TRAIN_BASE_PATH}/{class_path}')\n",
    "#     samples_in_class = len(class_file)\n",
    "#     samples_in_class = min(samples_in_class, NUM_SAMPLE_FOR_CLASS)\n",
    "#     \n",
    "#     train_samples_files = class_file[:samples_in_class]\n",
    "#     train_samples_files = list(map(lambda x: f'{TRAIN_BASE_PATH}/{class_path}/{x}', train_samples_files))\n",
    "#     train_samples_images = list(map(lambda x: Image.open(x), train_samples_files))\n",
    "#     \n",
    "#     payload = DataFrame.from_records({\n",
    "#         'image_path': train_samples_files,\n",
    "#     })\n",
    "#     payload['type'] = class_path\n",
    "#     df = pd.concat([df, payload])\n",
    "# df"
   ],
   "id": "5a394e506ee8f19b",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:43:51.665188Z",
     "start_time": "2024-06-11T15:43:51.659151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import os\n",
    "# \n",
    "# train_files = os.listdir('../afhq/train/cat')\n",
    "# \n",
    "# train_samples_files = train_files[:200]\n",
    "# train_samples_files = list(map(lambda x: f'../afhq/train/cat/{x}', train_samples_files))\n",
    "# train_samples_images = list(map(lambda x: Image.open(x), train_samples_files))"
   ],
   "id": "e07c67d0475f330f",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:43:51.670882Z",
     "start_time": "2024-06-11T15:43:51.666583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# payload = DataFrame.from_records({\n",
    "#         'image_path': train_samples_files,\n",
    "#     })\n",
    "# payload['type'] = 'cat'\n",
    "# payload"
   ],
   "id": "bcaf8ce048431e3d",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:43:51.677845Z",
     "start_time": "2024-06-11T15:43:51.672892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from io import BytesIO\n",
    "# import math\n",
    "# import base64\n",
    "# \n",
    "# target_width = 256\n",
    "# def resize_image(image_path):\n",
    "#     pil_img = Image.open(image_path)\n",
    "#     image_aspect_ratio = pil_img.size[0] / pil_img.size[1]\n",
    "#     resized_img = pil_img.resize(\n",
    "#         [target_width, math.floor(target_width * image_aspect_ratio)]\n",
    "#     )\n",
    "#     return resized_img\n",
    "# \n",
    "# def convert_image_to_base64(image):\n",
    "#     buffered = BytesIO()\n",
    "#     image.save(buffered, format=\"JPEG\")\n",
    "#     return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "# \n",
    "# \n",
    "# resized_images = list(map( lambda x: resize_image(x), train_samples_files))\n",
    "# base64_str = list(map( lambda x: convert_image_to_base64(x), resized_images))\n",
    "# payload['image'] = base64_str"
   ],
   "id": "ce11f93266d87380",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:43:51.684506Z",
     "start_time": "2024-06-11T15:43:51.678853Z"
    }
   },
   "cell_type": "code",
   "source": "# payload",
   "id": "5efa8b2a3117c984",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:43:51.688356Z",
     "start_time": "2024-06-11T15:43:51.685523Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "78bcf59c3f181bd2",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:43:51.692583Z",
     "start_time": "2024-06-11T15:43:51.689365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# resized_images = []\n",
    "# for i in range(len(data)):\n",
    "#     resized_image, _, _ = data[i]\n",
    "#     resized_images.append(resized_image)\n",
    "# resized_images"
   ],
   "id": "133cc641bf3cbf4b",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:43:51.699563Z",
     "start_time": "2024-06-11T15:43:51.693589Z"
    }
   },
   "cell_type": "code",
   "source": "# len(matcher)",
   "id": "ce3ebfb0ff840fd1",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:43:51.705587Z",
     "start_time": "2024-06-11T15:43:51.700592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# resized_images = []\n",
    "# for i in range(50):\n",
    "#     _, image, _ = matcher[i]\n",
    "#     resized_images.append(image)\n",
    "#     \n",
    "# len(resized_images)"
   ],
   "id": "5ddcd61c18700a3a",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:43:51.711586Z",
     "start_time": "2024-06-11T15:43:51.706595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from transformers import AutoImageProcessor, ResNetForImageClassification\n",
    "# \n",
    "# processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-18\")\n",
    "# model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-18\")\n",
    "# \n",
    "# inputs = processor(images=resized_images, return_tensors=\"pt\")\n",
    "# outputs = model(**inputs)"
   ],
   "id": "5d84736b4272ad58",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:43:51.718031Z",
     "start_time": "2024-06-11T15:43:51.712596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# del resized_images\n",
    "# matcher[0][3].shape # => [1, 1000]"
   ],
   "id": "f063f8a0c6d4597c",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:43:51.724547Z",
     "start_time": "2024-06-11T15:43:51.719041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# embeddings = outputs.logits\n",
    "# embeddings_length = embeddings.shape[1]\n",
    "# embeddings, embeddings_length"
   ],
   "id": "1fb2f983679e38a3",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:45:22.495633Z",
     "start_time": "2024-06-11T15:45:22.492592Z"
    }
   },
   "cell_type": "code",
   "source": "# n_selected = 1000",
   "id": "9235f2e50ee623bb",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:44:27.212181Z",
     "start_time": "2024-06-11T15:44:24.067554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from qdrant_client.models import VectorParams, Distance\n",
    "# \n",
    "# collection_name = 'instagram_data'\n",
    "# collection = qdrant_client.create_collection(\n",
    "#     collection_name=collection_name,\n",
    "#     vectors_config=VectorParams(\n",
    "#         size=matcher[0][3].shape[1],\n",
    "#         distance=Distance.COSINE\n",
    "#     ),\n",
    "# )\n",
    "# collection"
   ],
   "id": "f75db53dbe87e55b",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:18:56.490556Z",
     "start_time": "2024-06-11T15:18:56.487637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# payload_2 = payload.copy()\n",
    "# payload_dicts = payload_2.to_dict(orient='records')\n",
    "# payload_dicts"
   ],
   "id": "bffb0fc692d66d31",
   "execution_count": 32,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:18:56.717874Z",
     "start_time": "2024-06-11T15:18:56.714405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from qdrant_client.grpc import PointStruct\n",
    "# from qdrant_client.grpc.points_pb2 import PointId\n",
    "# \n",
    "# points = []\n",
    "# for idx, payload_dict in enumerate(payload):\n",
    "#     point_id = PointId(num=idx)  # Create a PointId object\n",
    "#     vector = embeddings[idx]\n",
    "#     payload = payload_dict\n",
    "# \n",
    "#     points.append(PointStruct(id=point_id, vector=vector, payload=payload))\n",
    "# \n",
    "# print(points)  # Now, you should see correctly structured PointStruct instances\n"
   ],
   "id": "b3b022b07183e2af",
   "execution_count": 33,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:18:56.960394Z",
     "start_time": "2024-06-11T15:18:56.957384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# data_dict = {}\n",
    "# for i in range(len(data)):\n",
    "#     image, image_type, encoded_image = data[i]\n",
    "#     data_dict[i] = {'type': image_type, 'image': encoded_image}"
   ],
   "id": "3dc4b887f6516569",
   "execution_count": 34,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:56:52.257560Z",
     "start_time": "2024-06-11T15:45:46.139070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# data_dict = {}\n",
    "# embeddings = []\n",
    "# for i in range(1000):\n",
    "#     data_dict[i] = {\n",
    "#         'instagram_user': matcher[i][0]['instagram_user'],\n",
    "#         'image_path': matcher[i][0]['image_path'],\n",
    "#         'link': matcher[i][0]['link'],\n",
    "#         'full_name': matcher[i][0]['full_name'],\n",
    "#         'bio': matcher[i][0]['bio'],\n",
    "#         'encoded_image': matcher[i][2],\n",
    "#     }\n",
    "#     embeddings.append(matcher[i][3])"
   ],
   "id": "d44f3aa5abc2f612",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:25:48.768585Z",
     "start_time": "2024-06-11T15:25:48.763027Z"
    }
   },
   "cell_type": "code",
   "source": "# data_dict[2]",
   "id": "6b6a210031a43236",
   "execution_count": 43,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:25:49.059866Z",
     "start_time": "2024-06-11T15:25:48.769593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from qdrant_client import models\n",
    "# points = [\n",
    "#     models.PointStruct(\n",
    "#         id=idx,\n",
    "#         payload=data_dict[idx],\n",
    "#         vector=embeddings[idx].flatten().tolist()\n",
    "#     )\n",
    "#     for idx, _ in enumerate(data_dict)\n",
    "# ]"
   ],
   "id": "5eb334b3fa5467d8",
   "execution_count": 44,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:25:49.064385Z",
     "start_time": "2024-06-11T15:25:49.061376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from qdrant_client import models\n",
    "# \n",
    "# points = [\n",
    "#     models.PointStruct(\n",
    "#         id=idx,\n",
    "#         payload=data_dict[idx],\n",
    "#         vector=embeddings[idx].tolist()\n",
    "#     )\n",
    "#     for idx, _ in enumerate(data_dict)\n",
    "# ]\n",
    "# points"
   ],
   "id": "37b9058b09483029",
   "execution_count": 45,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "matcher",
   "id": "6e69128cd0a75bdb",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:25:53.455862Z",
     "start_time": "2024-06-11T15:25:49.064892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# qdrant_client.upsert(\n",
    "#     collection_name=collection_name,\n",
    "#     points=points\n",
    "# )"
   ],
   "id": "dd308b52c7a9e01c",
   "execution_count": 46,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T14:36:36.548650Z",
     "start_time": "2024-06-11T14:36:36.548650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# qdrant_client.upload_points(\n",
    "#     collection_name=collection_name,\n",
    "#     points=points\n",
    "# )"
   ],
   "id": "9054f087d6d03b79",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f01874786a2989fb",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
